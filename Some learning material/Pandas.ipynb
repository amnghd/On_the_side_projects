{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (basics and advanced)\n",
    "\n",
    "Built on top of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a data frame \n",
    "weights = np.random.normal(loc = 130, scale = 50, size =250) # 250 random weights\n",
    "heights = np.random.normal(loc = 5.5, scale = 1, size = 250)\n",
    "gender_dict = {1:'female', 0:'male'}\n",
    "gender = np.random.binomial(1,0.5,250)\n",
    "gender = [gender_dict[i] for i in gender]\n",
    "age_dict = {0:'todler', 1:'young', 2:'senior'}\n",
    "age = np.random.binomial(2, 0.5, 250) # more young less todler and seniors\n",
    "age = [age_dict[i] for i in age]\n",
    "data_frame_dict = {'weigh':weights, 'height':heights, 'gender':gender, 'age_group':age}\n",
    "demographic = pd.DataFrame(data_frame_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing data into dataframes\n",
    "[This](https://www.datacamp.com/community/tutorials/pandas-read-csv) article is a good explanation of some of pandas.read_csv() arguments.\n",
    "\n",
    "``skiprows``: when you have a csv file that has a few rows above the data that is not part of data, you can choose how many rows to skip. ``skiprows = 4``\n",
    "\n",
    "``na_values``: when your csv file has some specific labeling for nan values such as 'missing', or'na', you can put these elements into a list and set it as an argument. na_values = `['missing', 'na', '.', 'not available']`\n",
    "\n",
    "``sep``: you can use read_csv to import tsv or psv, just define sep='\\t' or sep='|'. If you dont define these, though, pandas can automatically detect it.\n",
    "\n",
    "``header``: row number to use as the header label of the data. Header is 0-indexed. You can use skiprows and header to reach the same goal. If you choose ``header=None`` the data frame has columns that has no labels. You need to set labels using ``name``.\n",
    "\n",
    "``name``: a list of names to be used as header for the dataframe. List should be a set of unique values.\n",
    "\n",
    "``index_col``: which column is used as the index. If a list is given, a mutliindex is used.\n",
    "\n",
    "``usecols``: list of columns to keep when importing. You can also use index of columns. This can be done after we import the data too. But if data is too big, we can use this paramter.\n",
    "\n",
    "``prefix``: if there is no header, the data is imported with 'untitled0','untitled1', ect. If we want to use names other that untitled, we can set it using prefix. For example, if we want col1, col2, col3, ... as our labels, we will use :prefix = 'col'.\n",
    "\n",
    "``engine``: you can use either 'c' or 'python'. C is faster but it has less functionalities. Use it if you data is very large.\n",
    "\n",
    "``nrows``: number of rows of files read. Useful for reading pieces of large files.\n",
    "\n",
    "**``parse_dates``**: you can set the datetime columns of your dataframe using this parameter. This will parse that column and return a datetime object from it. This parameter is very flexible. You can give it a single columns, or few columns that each are timestamps, or concatanataion of few columns. \n",
    "\n",
    "``infer_datetime_format``: If the parse_date is enabled, and you set infer_datetime_format = True, the parsing becomes faster.\n",
    "\n",
    "``chunksize``: you set number of rows of dataset to be read, you can iterate over this iterator and perform your data analysis in a streaming manner. Note that since this will generate an iterator, once you peform the iteration on it, it will yield all of its values and become empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2keep = [\n",
    " 'housing_median_age',\n",
    " 'total_rooms',\n",
    " 'total_bedrooms',\n",
    " 'population',\n",
    " 'households',\n",
    " 'median_income',\n",
    " 'median_house_value']\n",
    "housing  = pd.read_csv('data/housing.csv', usecols=cols2keep, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(housing):\n",
    "    print(i+1,'-th chunk median income:\\t$k', round(np.median(chunk.median_income),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets import the file into dataframe and start playing with it\n",
    "col_names = [\n",
    " 'long',\n",
    " 'lat',\n",
    " 'median_age',\n",
    " 'num_room',\n",
    " 'num_bedroom',\n",
    " 'population',\n",
    " 'households',\n",
    " 'median_income',\n",
    " 'median_price',\n",
    " 'ocean_proximit']\n",
    "housing = pd.read_csv('data/housing.csv', names=col_names, engine='c', skiprows=1)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing data frames\n",
    "\n",
    "##### slicing based on one column as a series\n",
    "Using single square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age_series = housing['median_age']\n",
    "type(median_age_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### slicing based on one or few column as dataframe\n",
    "Using double square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age_df = housing[['median_age']]\n",
    "median_age_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_income = housing[['median_income', 'population']]\n",
    "population_income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### slicing based on row index\n",
    "Use ``iloc``.\n",
    "``iloc`` is based on the intrinsic ordering of the dataframe. There is also ``loc`` that filters based on the index that has been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_fives = housing.iloc[:5]\n",
    "first_fives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a very non-standard way of doing this which is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_nstandard = housing[:5]\n",
    "first_five_nstandard.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### slicing based on a condition(filtering)\n",
    "Use loc, iloc, or simple square bracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask = (housing.num_room > 2500) & (housing.median_age > 45)\n",
    "crowded_old = housing[boolean_mask]\n",
    "crowded_old.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowded_old = housing.loc[boolean_mask]\n",
    "crowded_old.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### slicing based on a condition for a column\n",
    "Use loc again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowded_old_income = housing.loc[boolean_mask, 'median_income'] # first element is the mask, second is the column\n",
    "crowded_old_income.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over dataframe columns, and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over columns\n",
    "for col in housing: # you just iterate over the dataframe\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the content\n",
    "housing_10 = housing[:10] # first ten rows\n",
    "for index, row in housing_10.iterrows():\n",
    "    print(\"Index: {}\\t Population: {}\".format(index, row['population']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a function to all the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['non_bedroom_rooms'] = housing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
